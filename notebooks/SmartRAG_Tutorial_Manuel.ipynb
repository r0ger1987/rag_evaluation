{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä √âvaluation RAG Manuel avec Ragas - Projet N√©o\n",
    "\n",
    "## üéØ Objectif\n",
    "√âvaluer la qualit√© d'un syst√®me RAG en utilisant les 5 m√©triques Ragas principales :\n",
    "1. **Faithfulness** : Fid√©lit√© aux sources (pas d'hallucination)\n",
    "2. **Answer Correctness** : Correction vs r√©f√©rence m√©tier\n",
    "3. **Answer Relevancy** : Pertinence √† la question\n",
    "4. **Context Precision** : Qualit√© du ranking des contextes\n",
    "5. **Context Recall** : Compl√©tude de la r√©cup√©ration\n",
    "\n",
    "## üìÅ Donn√©es utilis√©es\n",
    "- Fichier CSV : `reference_qa_manuel_template.csv`\n",
    "- 12 questions du Projet N√©o avec r√©ponses de r√©f√©rence\n",
    "- Contextes format√©s avec s√©parateur `|||`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by conda-forge | (main, Jun 16 2025, 08:27:50) [GCC 13.3.0]\n",
      "OS: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ragas: 0.3.2\n",
      "langchain: 0.3.27\n",
      "datasets: 4.0.0\n",
      "pandas: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# Ex√©cutez cette cellule si besoin (versions recommand√©es).\n",
    "# Si vous √™tes hors ligne, installez ces paquets au pr√©alable dans votre environnement.\n",
    "# !pip install \"ragas>=0.3.1,<0.4\" \"langchain>=0.2\" \"datasets>=2.20\" pandas tiktoken\n",
    "\n",
    "import sys, platform, importlib\n",
    "\n",
    "def check_pkg(name):\n",
    "    try:\n",
    "        m = importlib.import_module(name)\n",
    "        return m.__version__ if hasattr(m, \"__version__\") else \"installed\"\n",
    "    except Exception as e:\n",
    "        return f\"not found: {e}\"\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"ragas:\", check_pkg(\"ragas\"))\n",
    "print(\"langchain:\", check_pkg(\"langchain\"))\n",
    "print(\"datasets:\", check_pkg(\"datasets\"))\n",
    "print(\"pandas:\", check_pkg(\"pandas\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: openai\n",
      "Data path: reference_qa_manuel_template.csv\n",
      "Output dir: outputs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# === Choix du fournisseur LLM ===\n",
    "# Options: \"openai\", \"claude\", \"gemini\", \"ollama\"\n",
    "RAGAS_LLM_PROVIDER = os.getenv(\"RAGAS_LLM_PROVIDER\", \"openai\").lower()\n",
    "\n",
    "# Mod√®les par d√©faut (changez si besoin)\n",
    "OPENAI_MODEL  = os.getenv(\"OPENAI_MODEL\",  \"gpt-4o-mini\")  # ou \"gpt-4o\"\n",
    "CLAUDE_MODEL  = os.getenv(\"CLAUDE_MODEL\",  \"claude-3-5-sonnet-20240620\")\n",
    "GEMINI_MODEL  = os.getenv(\"GEMINI_MODEL\",  \"gemini-1.5-pro\")\n",
    "OLLAMA_MODEL  = os.getenv(\"OLLAMA_MODEL\",  \"llama3.1:8b\")\n",
    "\n",
    "# Cl√©s d'API attendues dans l'environnement (ne les mettez pas en dur dans le notebook)\n",
    "os.environ[\"OPENAI_API_KEY\"]     = \"\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"]  = \"...\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"]     = \"...\"\n",
    "\n",
    "# === Donn√©es ===\n",
    "# Si vous ex√©cutez ce notebook localement, placez votre CSV dans le m√™me dossier que le notebook\n",
    "# ou indiquez le chemin absolu complet ci-dessous.\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\", \"reference_qa_manuel_template.csv\")\n",
    "\n",
    "# Dossiers de sortie\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\", \"outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Provider:\", RAGAS_LLM_PROVIDER)\n",
    "print(\"Data path:\", DATA_PATH)\n",
    "print(\"Output dir:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Chargement du CSV et aper√ßu des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DATA_PATH non trouv√©, utilisation de ../data/reference/reference_qa_manuel_template.csv\n",
      "Shape: (12, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>sharepoint_document</th>\n",
       "      <th>ragas_question</th>\n",
       "      <th>ragas_answer</th>\n",
       "      <th>ragas_contexts</th>\n",
       "      <th>ragas_ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QNeo001</td>\n",
       "      <td>Qui est le chef de projet du Projet N√©o ?</td>\n",
       "      <td>Marc Dubois est le chef de projet du Projet N√©o.</td>\n",
       "      <td>Note de cadrage - Projet Neo.txt</td>\n",
       "      <td>Qui est le chef de projet du Projet N√©o ?</td>\n",
       "      <td>Marc Dubois est le chef de projet du Projet N√©...</td>\n",
       "      <td>[Document: Note de cadrage - Projet Neo.txt] L...</td>\n",
       "      <td>Note de cadrage - Projet Neo.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QNeo002</td>\n",
       "      <td>Quel est l'objectif principal du Projet N√©o ?</td>\n",
       "      <td>Le Projet N√©o vise √† d√©velopper un nouvel algo...</td>\n",
       "      <td>Note de cadrage - Projet Neo.txt</td>\n",
       "      <td>Quel est l'objectif principal du Projet N√©o ?</td>\n",
       "      <td>L'objectif du Projet N√©o est de d√©velopper un ...</td>\n",
       "      <td>[Document: Note de cadrage - Projet Neo.txt] L...</td>\n",
       "      <td>Note de cadrage - Projet Neo.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QNeo003</td>\n",
       "      <td>Qui est le lead developer assign√© au projet ?</td>\n",
       "      <td>Sophie Martin est le lead developer assign√© au...</td>\n",
       "      <td>Note de cadrage - Projet Neo.txt</td>\n",
       "      <td>Qui est le lead developer assign√© au projet ?</td>\n",
       "      <td>Sophie Martin est d√©sign√©e comme Lead Develope...</td>\n",
       "      <td>[Document: Note de cadrage - Projet Neo.txt] L...</td>\n",
       "      <td>Note de cadrage - Projet Neo.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QNeo004</td>\n",
       "      <td>Quelles sont les comp√©tences de David Chen ?</td>\n",
       "      <td>David Chen poss√®de des comp√©tences en Python, ...</td>\n",
       "      <td>Repertoire equipe - Projet Neo.txt</td>\n",
       "      <td>Quelles sont les comp√©tences de David Chen ?</td>\n",
       "      <td>David Chen, Data Scientist Principal, ma√Ætrise...</td>\n",
       "      <td>[Document: Repertoire equipe - Projet Neo.txt]...</td>\n",
       "      <td>Repertoire equipe - Projet Neo.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QNeo005</td>\n",
       "      <td>Qui est le manager de Sophie Martin ?</td>\n",
       "      <td>Marc Dubois est le manager de Sophie Martin.</td>\n",
       "      <td>Repertoire equipe - Projet Neo.txt</td>\n",
       "      <td>Qui est le manager de Sophie Martin ?</td>\n",
       "      <td>Marc Dubois est le manager de Sophie Martin se...</td>\n",
       "      <td>[Document: Repertoire equipe - Projet Neo.txt]...</td>\n",
       "      <td>Repertoire equipe - Projet Neo.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_id                                       question  \\\n",
       "0     QNeo001      Qui est le chef de projet du Projet N√©o ?   \n",
       "1     QNeo002  Quel est l'objectif principal du Projet N√©o ?   \n",
       "2     QNeo003  Qui est le lead developer assign√© au projet ?   \n",
       "3     QNeo004   Quelles sont les comp√©tences de David Chen ?   \n",
       "4     QNeo005          Qui est le manager de Sophie Martin ?   \n",
       "\n",
       "                                    reference_answer  \\\n",
       "0   Marc Dubois est le chef de projet du Projet N√©o.   \n",
       "1  Le Projet N√©o vise √† d√©velopper un nouvel algo...   \n",
       "2  Sophie Martin est le lead developer assign√© au...   \n",
       "3  David Chen poss√®de des comp√©tences en Python, ...   \n",
       "4       Marc Dubois est le manager de Sophie Martin.   \n",
       "\n",
       "                  sharepoint_document  \\\n",
       "0    Note de cadrage - Projet Neo.txt   \n",
       "1    Note de cadrage - Projet Neo.txt   \n",
       "2    Note de cadrage - Projet Neo.txt   \n",
       "3  Repertoire equipe - Projet Neo.txt   \n",
       "4  Repertoire equipe - Projet Neo.txt   \n",
       "\n",
       "                                  ragas_question  \\\n",
       "0      Qui est le chef de projet du Projet N√©o ?   \n",
       "1  Quel est l'objectif principal du Projet N√©o ?   \n",
       "2  Qui est le lead developer assign√© au projet ?   \n",
       "3   Quelles sont les comp√©tences de David Chen ?   \n",
       "4          Qui est le manager de Sophie Martin ?   \n",
       "\n",
       "                                        ragas_answer  \\\n",
       "0  Marc Dubois est le chef de projet du Projet N√©...   \n",
       "1  L'objectif du Projet N√©o est de d√©velopper un ...   \n",
       "2  Sophie Martin est d√©sign√©e comme Lead Develope...   \n",
       "3  David Chen, Data Scientist Principal, ma√Ætrise...   \n",
       "4  Marc Dubois est le manager de Sophie Martin se...   \n",
       "\n",
       "                                      ragas_contexts  \\\n",
       "0  [Document: Note de cadrage - Projet Neo.txt] L...   \n",
       "1  [Document: Note de cadrage - Projet Neo.txt] L...   \n",
       "2  [Document: Note de cadrage - Projet Neo.txt] L...   \n",
       "3  [Document: Repertoire equipe - Projet Neo.txt]...   \n",
       "4  [Document: Repertoire equipe - Projet Neo.txt]...   \n",
       "\n",
       "                   ragas_ground_truth  \n",
       "0    Note de cadrage - Projet Neo.txt  \n",
       "1    Note de cadrage - Projet Neo.txt  \n",
       "2    Note de cadrage - Projet Neo.txt  \n",
       "3  Repertoire equipe - Projet Neo.txt  \n",
       "4  Repertoire equipe - Projet Neo.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes: ['question_id', 'question', 'reference_answer', 'sharepoint_document', 'ragas_question', 'ragas_answer', 'ragas_contexts', 'ragas_ground_truth']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    \n",
    "    alt_path = '../data/reference/reference_qa_manuel_template.csv'\n",
    "    if os.path.exists(alt_path):\n",
    "        DATA_PATH = alt_path\n",
    "        print(f\"INFO: DATA_PATH non trouv√©, utilisation de {alt_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"CSV introuvable: {DATA_PATH}\")\n",
    "\n",
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", raw_df.shape)\n",
    "display(raw_df.head(5))\n",
    "print(\"Colonnes:\", list(raw_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Normalisation du dataset pour RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : <class 'list'> (len=12)\n",
      "answer : <class 'list'> (len=12)\n",
      "contexts : <class 'list'> (len=12)\n",
      "ground_truth : <class 'list'> (len=12)\n",
      "Exemple contexts[0]: ['[Document: Note de cadrage - Projet Neo.txt] Le Projet N√©o vise √† d√©velopper un nouvel algorithme de recommandation pour notre plateforme e-commerce.', \"[Document: Note de cadrage - Projet Neo.txt] L'√©quipe cl√© comprend Marc Dubois comme Chef de Projet, Sophie Martin comme Lead Developer et David Chen comme Expert Data Science.\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ast\n",
    "import math\n",
    "\n",
    "df = raw_df.copy()\n",
    "\n",
    "# === Mapping des colonnes pr√©sentes dans votre CSV ===\n",
    "# Votre CSV inclut (exemple): question, ragas_answer, ragas_contexts, reference_answer\n",
    "# On mappe vers les colonnes attendues par RAGAS : question, answer, contexts (List[str]), ground_truth (str)\n",
    "QUESTION_COL   = \"question\"          # ou \"ragas_question\"\n",
    "ANSWER_COL     = \"ragas_answer\"      # r√©ponse mod√®le\n",
    "CONTEXTS_COL   = \"ragas_contexts\"    # passages r√©cup√©r√©s (un ou plusieurs)\n",
    "GROUNDTRUTH_COL_IN = \"reference_answer\"  # v√©rit√© terrain m√©tier (texte)\n",
    "\n",
    "if QUESTION_COL not in df.columns:\n",
    "    # fallback si besoin\n",
    "    if \"ragas_question\" in df.columns:\n",
    "        QUESTION_COL = \"ragas_question\"\n",
    "    else:\n",
    "        raise KeyError(\"Aucune colonne question d√©tect√©e. Attendu 'question' ou 'ragas_question'.\")\n",
    "\n",
    "if ANSWER_COL not in df.columns:\n",
    "    # fallback si besoin\n",
    "    if \"answer\" in df.columns:\n",
    "        ANSWER_COL = \"answer\"\n",
    "    else:\n",
    "        raise KeyError(\"Aucune colonne answer d√©tect√©e. Attendu 'ragas_answer' ou 'answer'.\")\n",
    "\n",
    "if CONTEXTS_COL not in df.columns:\n",
    "    if \"contexts\" in df.columns:\n",
    "        CONTEXTS_COL = \"contexts\"\n",
    "    else:\n",
    "        raise KeyError(\"Aucune colonne contexts d√©tect√©e. Attendu 'ragas_contexts' ou 'contexts'.\")\n",
    "\n",
    "if GROUNDTRUTH_COL_IN not in df.columns:\n",
    "    # fallback si besoin\n",
    "    if \"reference\" in df.columns:\n",
    "        GROUNDTRUTH_COL_IN = \"reference\"\n",
    "    elif \"ground_truth\" in df.columns:\n",
    "        GROUNDTRUTH_COL_IN = \"ground_truth\"\n",
    "    else:\n",
    "        raise KeyError(\"Aucune ground truth d√©tect√©e. Attendu 'reference_answer' ou 'reference' ou 'ground_truth'.\")\n",
    "\n",
    "def to_list_contexts(x):\n",
    "    \"\"\"Convertit la colonne contexts en List[str].\n",
    "    - Si d√©j√† une liste (str format√©e comme '[\"a\",\"b\"]'), on la parse avec ast.literal_eval\n",
    "    - Si s√©parateur '|||' ou ';' -> on split\n",
    "    - Sinon -> liste √† un √©l√©ment\n",
    "    \"\"\"\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(xx) for xx in x]\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        # Cas liste d√©j√† s√©rialis√©e\n",
    "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, (list, tuple)):\n",
    "                    return [str(xx) for xx in parsed]\n",
    "            except Exception:\n",
    "                pass\n",
    "        # S√©parateurs courants\n",
    "        for sep in [\"|||\", \"¬ß¬ß\", \";;\", \"##\", \"\\n\"]:\n",
    "            if sep in s:\n",
    "                return [ss.strip() for ss in s.split(sep) if ss.strip()]\n",
    "        # Fallback: un seul contexte\n",
    "        return [s]\n",
    "    # Autres types -> string\n",
    "    return [str(x)]\n",
    "\n",
    "dataset_dict = {\n",
    "    \"question\":     df[QUESTION_COL].astype(str).tolist(),\n",
    "    \"answer\":       df[ANSWER_COL].astype(str).tolist(),\n",
    "    \"contexts\":     [to_list_contexts(v) for v in df[CONTEXTS_COL].tolist()],\n",
    "    \"ground_truth\": df[GROUNDTRUTH_COL_IN].astype(str).tolist(),  # mapping important pour answer_correctness\n",
    "}\n",
    "\n",
    "# Sanity check rapide\n",
    "for k, v in dataset_dict.items():\n",
    "    print(k, \":\", type(v), f\"(len={len(v)})\")\n",
    "print(\"Exemple contexts[0]:\", dataset_dict[\"contexts\"][0][:2] if dataset_dict[\"contexts\"] else \"n/a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Construction du Dataset \n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "hf_dataset = HFDataset.from_dict(dataset_dict)\n",
    "hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Les 5 M√©triques Ragas Expliqu√©es\n",
    "\n",
    "### 1. üéØ **Faithfulness** (Fid√©lit√©) - Score 0-1\n",
    "- **Mesure** : La r√©ponse est-elle factuellement coh√©rente avec les contextes ?\n",
    "- **Donn√©es** : `contexts` + `answer`\n",
    "- **Objectif** : D√©tecter les hallucinations\n",
    "\n",
    "### 2. ‚úÖ **Answer Correctness** (Correction) - Score 0-1\n",
    "- **Mesure** : La r√©ponse est-elle correcte vs r√©f√©rence m√©tier ?\n",
    "- **Donn√©es** : `answer` + `reference`\n",
    "- **Objectif** : Valider la conformit√© m√©tier\n",
    "\n",
    "### 3. üí¨ **Answer Relevancy** (Pertinence) - Score 0-1\n",
    "- **Mesure** : La r√©ponse r√©pond-elle √† la question ?\n",
    "- **Donn√©es** : `question` + `answer`\n",
    "- **Objectif** : √âviter les r√©ponses hors-sujet\n",
    "\n",
    "### 4. üéØ **Context Precision** (Pr√©cision) - Score 0-1\n",
    "- **Mesure** : Les contextes pertinents sont-ils bien class√©s ?\n",
    "- **Donn√©es** : `question` + `contexts` + `ground_truths`\n",
    "- **Objectif** : √âvaluer le ranking\n",
    "\n",
    "### 5. üìö **Context Recall** (Rappel) - Score 0-1\n",
    "- **Mesure** : Tous les contextes importants r√©cup√©r√©s ?\n",
    "- **Donn√©es** : `contexts` + `ground_truths`\n",
    "- **Objectif** : √âvaluer la compl√©tude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Pr√©paration du Dataset Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM pr√™t pour RAGAS: LangchainLLMWrapper | provider: openai\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "def build_llm(provider: str):\n",
    "    provider = provider.lower().strip()\n",
    "    if provider == \"openai\":\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        lc = ChatOpenAI(model=OPENAI_MODEL, temperature=0)\n",
    "        return LangchainLLMWrapper(lc)\n",
    "    elif provider == \"claude\":\n",
    "        from langchain_anthropic import ChatAnthropic\n",
    "        lc = ChatAnthropic(model=CLAUDE_MODEL, temperature=0)\n",
    "        return LangchainLLMWrapper(lc)\n",
    "    elif provider == \"gemini\":\n",
    "        from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "        lc = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=0)\n",
    "        return LangchainLLMWrapper(lc)\n",
    "    elif provider == \"ollama\":\n",
    "        # Selon la version de LangChain : ChatOllama (chat) ou Ollama (llm)\n",
    "        try:\n",
    "            from langchain_community.chat_models import ChatOllama\n",
    "            lc = ChatOllama(model=OLLAMA_MODEL)\n",
    "        except Exception:\n",
    "            from langchain_community.llms import Ollama\n",
    "            lc = Ollama(model=OLLAMA_MODEL)\n",
    "        return LangchainLLMWrapper(lc)\n",
    "    else:\n",
    "        raise ValueError(f\"Provider non support√©: {provider}\")\n",
    "\n",
    "llm = build_llm(RAGAS_LLM_PROVIDER)\n",
    "print(\"‚úÖ LLM pr√™t pour RAGAS:\", type(llm).__name__, \"| provider:\", RAGAS_LLM_PROVIDER)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ D√©finition des m√©triques ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Faithfulness(_required_columns={<MetricType.SINGLE_TURN: 'single_turn'>: {'response', 'user_input', 'retrieved_contexts'}}, name='faithfulness', llm=None, output_type=<MetricOutputType.CONTINUOUS: 'continuous'>, nli_statements_prompt=NLIStatementPrompt(instruction=Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context., examples=[(NLIStatementInput(context='John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', statements=['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.']), NLIStatementOutput(statements=[StatementFaithfulnessAnswer(statement='John is majoring in Biology.', reason=\"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", verdict=0), StatementFaithfulnessAnswer(statement='John is taking a course on Artificial Intelligence.', reason='The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', verdict=0), StatementFaithfulnessAnswer(statement='John is a dedicated student.', reason='The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', verdict=1), StatementFaithfulnessAnswer(statement='John has a part-time job.', reason='There is no information given in the context about John having a part-time job.', verdict=0)])), (NLIStatementInput(context='Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', statements=['Albert Einstein was a genius.']), NLIStatementOutput(statements=[StatementFaithfulnessAnswer(statement='Albert Einstein was a genius.', reason='The context and statement are unrelated', verdict=0)]))], language=english), statement_generator_prompt=StatementGeneratorPrompt(instruction=Given a question and an answer, analyze the complexity of each sentence in the answer. Break down each sentence into one or more fully understandable statements. Ensure that no pronouns are used in any statement. Format the outputs in JSON., examples=[(StatementGeneratorInput(question='Who was Albert Einstein and what is he best known for?', answer='He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.'), StatementGeneratorOutput(statements=['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.', 'Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']))], language=english), max_retries=1),\n",
       " AnswerCorrectness(_required_columns={<MetricType.SINGLE_TURN: 'single_turn'>: {'response', 'user_input', 'reference'}}, name='answer_correctness', embeddings=None, llm=None, output_type=None, correctness_prompt=CorrectnessClassifier(instruction=Given a ground truth and an answer statements, analyze each statement and classify them in one of the following categories: TP (true positive): statements that are present in answer that are also directly supported by the one or more statements in ground truth, FP (false positive): statements present in the answer but not directly supported by any statement in ground truth, FN (false negative): statements found in the ground truth but not present in answer. Each statement can only belong to one of the categories. Provide a reason for each classification., examples=[(QuestionAnswerGroundTruth(question='What powers the sun and what is its primary function?', answer=['The sun is powered by nuclear fission, similar to nuclear reactors on Earth.', 'The primary function of the sun is to provide light to the solar system.'], ground_truth=['The sun is powered by nuclear fusion, where hydrogen atoms fuse to form helium.', \"This fusion process in the sun's core releases a tremendous amount of energy.\", 'The energy from the sun provides heat and light, which are essential for life on Earth.', \"The sun's light plays a critical role in Earth's climate system.\", 'Sunlight helps to drive the weather and ocean currents.']), ClassificationWithReason(TP=[StatementsWithReason(statement='The primary function of the sun is to provide light to the solar system.', reason=\"This statement is somewhat supported by the ground truth mentioning the sun providing light and its roles, though it focuses more broadly on the sun's energy.\")], FP=[StatementsWithReason(statement='The sun is powered by nuclear fission, similar to nuclear reactors on Earth.', reason='This statement is incorrect and contradicts the ground truth which states that the sun is powered by nuclear fusion.')], FN=[StatementsWithReason(statement='The sun is powered by nuclear fusion, where hydrogen atoms fuse to form helium.', reason='This accurate description of the sun‚Äôs power source is not included in the answer.'), StatementsWithReason(statement=\"This fusion process in the sun's core releases a tremendous amount of energy.\", reason='This process and its significance are not mentioned in the answer.'), StatementsWithReason(statement='The energy from the sun provides heat and light, which are essential for life on Earth.', reason='The answer only mentions light, omitting the essential aspects of heat and its necessity for life, which the ground truth covers.'), StatementsWithReason(statement=\"The sun's light plays a critical role in Earth's climate system.\", reason=\"This broader impact of the sun‚Äôs light on Earth's climate system is not addressed in the answer.\"), StatementsWithReason(statement='Sunlight helps to drive the weather and ocean currents.', reason='The effect of sunlight on weather patterns and ocean currents is omitted in the answer.')])), (QuestionAnswerGroundTruth(question='What is the boiling point of water?', answer=['The boiling point of water is 100 degrees Celsius at sea level'], ground_truth=['The boiling point of water is 100 degrees Celsius (212 degrees Fahrenheit) at sea level.', 'The boiling point of water can change with altitude.']), ClassificationWithReason(TP=[StatementsWithReason(statement='The boiling point of water is 100 degrees Celsius at sea level', reason='This statement is directly supported by the ground truth which specifies the boiling point of water as 100 degrees Celsius at sea level.')], FP=[], FN=[StatementsWithReason(statement='The boiling point of water can change with altitude.', reason='This additional information about how the boiling point of water can vary with altitude is not mentioned in the answer.')]))], language=english), statement_generator_prompt=StatementGeneratorPrompt(instruction=Given a question and an answer, analyze the complexity of each sentence in the answer. Break down each sentence into one or more fully understandable statements. Ensure that no pronouns are used in any statement. Format the outputs in JSON., examples=[(StatementGeneratorInput(question='Who was Albert Einstein and what is he best known for?', answer='He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.'), StatementGeneratorOutput(statements=['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.', 'Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']))], language=english), weights=[0.75, 0.25], beta=1.0, answer_similarity=None, max_retries=1),\n",
       " AnswerRelevancy(_required_columns={<MetricType.SINGLE_TURN: 'single_turn'>: {'response', 'user_input'}}, name='answer_relevancy', embeddings=None, llm=None, output_type=None, question_generation=ResponseRelevancePrompt(instruction=Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don't know\" or \"I'm not sure\" are noncommittal answers, examples=[(ResponseRelevanceInput(response='Albert Einstein was born in Germany.'), ResponseRelevanceOutput(question='Where was Albert Einstein born?', noncommittal=0)), (ResponseRelevanceInput(response=\"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \"), ResponseRelevanceOutput(question='What was the groundbreaking feature of the smartphone invented in 2023?', noncommittal=1))], language=english), strictness=3),\n",
       " ContextPrecision(_required_columns={<MetricType.SINGLE_TURN: 'single_turn'>: {'user_input', 'reference', 'retrieved_contexts'}}, name='context_precision', llm=None, output_type=None, context_precision_prompt=ContextPrecisionPrompt(instruction=Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output., examples=[(QAC(question='What can you tell me about Albert Einstein?', context=\"Albert Einstein (14 March 1879 ‚Äì 18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass‚Äìenergy equivalence formula E = mc2, which arises from relativity theory, has been called 'the world's most famous equation'. He received the 1921 Nobel Prize in Physics 'for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect', a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.\", answer='Albert Einstein, born on 14 March 1879, was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics.'), Verification(reason=\"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", verdict=1)), (QAC(question='who won 2020 icc world cup?', context=\"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", answer='England'), Verification(reason='the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', verdict=1)), (QAC(question='What is the tallest mountain in the world?', context='The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', answer='Mount Everest.'), Verification(reason=\"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", verdict=0))], language=english), max_retries=1),\n",
       " ContextRecall(_required_columns={<MetricType.SINGLE_TURN: 'single_turn'>: {'user_input', 'reference', 'retrieved_contexts'}}, name='context_recall', llm=None, output_type=<MetricOutputType.CONTINUOUS: 'continuous'>, context_recall_prompt=ContextRecallClassificationPrompt(instruction=Given a context, and an answer, analyze each sentence in the answer and classify if the sentence can be attributed to the given context or not. Use only 'Yes' (1) or 'No' (0) as a binary classification. Output json with reason., examples=[(QCA(question='What can you tell me about albert Albert Einstein?', context=\"Albert Einstein (14 March 1879 - 18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass-energy equivalence formula E = mc2, which arises from relativity theory, has been called 'the world's most famous equation'. He received the 1921 Nobel Prize in Physics 'for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect', a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.\", answer='Albert Einstein born in 14 March 1879 was  German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905.  Einstein moved to Switzerland in 1895'), ContextRecallClassifications(classifications=[ContextRecallClassification(statement='Albert Einstein, born on 14 March 1879, was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time.', reason='The date of birth of Einstein is mentioned clearly in the context.', attributed=1), ContextRecallClassification(statement='He received the 1921 Nobel Prize in Physics for his services to theoretical physics.', reason='The exact sentence is present in the given context.', attributed=1), ContextRecallClassification(statement='He published 4 papers in 1905.', reason='There is no mention about papers he wrote in the given context.', attributed=0), ContextRecallClassification(statement='Einstein moved to Switzerland in 1895.', reason='There is no supporting evidence for this in the given context.', attributed=0)]))], language=english), max_retries=1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_correctness,\n",
    "    answer_relevancy,   # ‚Üê au lieu de response_relevancy\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_correctness,\n",
    "    answer_relevancy,   # ‚Üê idem ici\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "]\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ √âvaluation avec Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:16<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ √âvaluation termin√©e.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qui est le chef de projet du Projet N√©o ?</td>\n",
       "      <td>[[Document: Note de cadrage - Projet Neo.txt] ...</td>\n",
       "      <td>Marc Dubois est le chef de projet du Projet N√©...</td>\n",
       "      <td>Marc Dubois est le chef de projet du Projet N√©o.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.743916</td>\n",
       "      <td>0.998186</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quel est l'objectif principal du Projet N√©o ?</td>\n",
       "      <td>[[Document: Note de cadrage - Projet Neo.txt] ...</td>\n",
       "      <td>L'objectif du Projet N√©o est de d√©velopper un ...</td>\n",
       "      <td>Le Projet N√©o vise √† d√©velopper un nouvel algo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.985759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qui est le lead developer assign√© au projet ?</td>\n",
       "      <td>[[Document: Note de cadrage - Projet Neo.txt] ...</td>\n",
       "      <td>Sophie Martin est d√©sign√©e comme Lead Develope...</td>\n",
       "      <td>Sophie Martin est le lead developer assign√© au...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996659</td>\n",
       "      <td>0.930813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quelles sont les comp√©tences de David Chen ?</td>\n",
       "      <td>[[Document: Repertoire equipe - Projet Neo.txt...</td>\n",
       "      <td>David Chen, Data Scientist Principal, ma√Ætrise...</td>\n",
       "      <td>David Chen poss√®de des comp√©tences en Python, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907657</td>\n",
       "      <td>0.881353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qui est le manager de Sophie Martin ?</td>\n",
       "      <td>[[Document: Repertoire equipe - Projet Neo.txt...</td>\n",
       "      <td>Marc Dubois est le manager de Sophie Martin se...</td>\n",
       "      <td>Marc Dubois est le manager de Sophie Martin.</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.745691</td>\n",
       "      <td>0.970598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quelle est la date limite pour le premier PoC ...</td>\n",
       "      <td>[[Document: Compte-Rendu de Reunion.txt] Proch...</td>\n",
       "      <td>Sophie Martin doit livrer un premier PoC (Proo...</td>\n",
       "      <td>Sophie Martin doit livrer un premier PoC (Proo...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.846984</td>\n",
       "      <td>0.932647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quel framework a √©t√© confirm√© pour le mod√®le p...</td>\n",
       "      <td>[[Document: Compte-Rendu de Reunion.txt] D√©cis...</td>\n",
       "      <td>TensorFlow a √©t√© confirm√© comme framework pour...</td>\n",
       "      <td>TensorFlow a √©t√© confirm√© comme framework pour...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741270</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qui dirige l'√©quipe Data Warehouse ?</td>\n",
       "      <td>[[Document: Repertoire equipe - Projet Neo.txt...</td>\n",
       "      <td>H√©l√®ne Petit occupe le poste de Directrice Dat...</td>\n",
       "      <td>H√©l√®ne Petit dirige l'√©quipe Data Warehouse.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621241</td>\n",
       "      <td>0.765512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quelle base de donn√©es est envisag√©e pour le p...</td>\n",
       "      <td>[[Document: Note de cadrage - Projet Neo.txt] ...</td>\n",
       "      <td>Neo4j est la base de donn√©es envisag√©e pour le...</td>\n",
       "      <td>Neo4j est envisag√© comme base de donn√©es pour ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995710</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quand est pr√©vue la revue de projet avec Carol...</td>\n",
       "      <td>[[Document: Compte-Rendu de Reunion.txt] Proch...</td>\n",
       "      <td>La revue de projet avec Carole Lambert est pro...</td>\n",
       "      <td>Une revue de projet est fix√©e avec Carole Lamb...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.990623</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0          Qui est le chef de projet du Projet N√©o ?   \n",
       "1      Quel est l'objectif principal du Projet N√©o ?   \n",
       "2      Qui est le lead developer assign√© au projet ?   \n",
       "3       Quelles sont les comp√©tences de David Chen ?   \n",
       "4              Qui est le manager de Sophie Martin ?   \n",
       "5  Quelle est la date limite pour le premier PoC ...   \n",
       "6  Quel framework a √©t√© confirm√© pour le mod√®le p...   \n",
       "7               Qui dirige l'√©quipe Data Warehouse ?   \n",
       "8  Quelle base de donn√©es est envisag√©e pour le p...   \n",
       "9  Quand est pr√©vue la revue de projet avec Carol...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [[Document: Note de cadrage - Projet Neo.txt] ...   \n",
       "1  [[Document: Note de cadrage - Projet Neo.txt] ...   \n",
       "2  [[Document: Note de cadrage - Projet Neo.txt] ...   \n",
       "3  [[Document: Repertoire equipe - Projet Neo.txt...   \n",
       "4  [[Document: Repertoire equipe - Projet Neo.txt...   \n",
       "5  [[Document: Compte-Rendu de Reunion.txt] Proch...   \n",
       "6  [[Document: Compte-Rendu de Reunion.txt] D√©cis...   \n",
       "7  [[Document: Repertoire equipe - Projet Neo.txt...   \n",
       "8  [[Document: Note de cadrage - Projet Neo.txt] ...   \n",
       "9  [[Document: Compte-Rendu de Reunion.txt] Proch...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Marc Dubois est le chef de projet du Projet N√©...   \n",
       "1  L'objectif du Projet N√©o est de d√©velopper un ...   \n",
       "2  Sophie Martin est d√©sign√©e comme Lead Develope...   \n",
       "3  David Chen, Data Scientist Principal, ma√Ætrise...   \n",
       "4  Marc Dubois est le manager de Sophie Martin se...   \n",
       "5  Sophie Martin doit livrer un premier PoC (Proo...   \n",
       "6  TensorFlow a √©t√© confirm√© comme framework pour...   \n",
       "7  H√©l√®ne Petit occupe le poste de Directrice Dat...   \n",
       "8  Neo4j est la base de donn√©es envisag√©e pour le...   \n",
       "9  La revue de projet avec Carole Lambert est pro...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0   Marc Dubois est le chef de projet du Projet N√©o.      1.000000   \n",
       "1  Le Projet N√©o vise √† d√©velopper un nouvel algo...      1.000000   \n",
       "2  Sophie Martin est le lead developer assign√© au...      1.000000   \n",
       "3  David Chen poss√®de des comp√©tences en Python, ...      1.000000   \n",
       "4       Marc Dubois est le manager de Sophie Martin.      0.500000   \n",
       "5  Sophie Martin doit livrer un premier PoC (Proo...      0.666667   \n",
       "6  TensorFlow a √©t√© confirm√© comme framework pour...      1.000000   \n",
       "7       H√©l√®ne Petit dirige l'√©quipe Data Warehouse.      1.000000   \n",
       "8  Neo4j est envisag√© comme base de donn√©es pour ...      1.000000   \n",
       "9  Une revue de projet est fix√©e avec Carole Lamb...      1.000000   \n",
       "\n",
       "   answer_correctness  answer_relevancy  context_precision  context_recall  \n",
       "0            0.743916          0.998186                0.5             1.0  \n",
       "1            0.993853          0.985759                1.0             1.0  \n",
       "2            0.996659          0.930813                1.0             1.0  \n",
       "3            0.907657          0.881353                1.0             1.0  \n",
       "4            0.745691          0.970598                1.0             1.0  \n",
       "5            0.846984          0.932647                1.0             1.0  \n",
       "6            0.741270          0.967857                1.0             1.0  \n",
       "7            0.621241          0.765512                1.0             1.0  \n",
       "8            0.995710          0.882434                1.0             1.0  \n",
       "9            0.996939          0.990623                0.5             1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©sultats enregistr√©s -> outputs/ragas_raw_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "# evaluate() accepte un HF Dataset + m√©triques + LLM\n",
    "# Pas besoin de column_map si vos cl√©s s'appellent d√©j√†: question, answer, contexts, ground_truth\n",
    "# (Nous avons mapp√© au pr√©alable 'reference_answer' -> 'ground_truth')\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=hf_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=llm,\n",
    "    raise_exceptions=False,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ √âvaluation termin√©e.\")\n",
    "df_results = result.to_pandas()\n",
    "display(df_results.head(10))\n",
    "\n",
    "# Sauvegarde brute\n",
    "csv_out = os.path.join(OUTPUT_DIR, \"ragas_raw_results.csv\")\n",
    "df_results.to_csv(csv_out, index=False, encoding=\"utf-8\")\n",
    "print(\"R√©sultats enregistr√©s ->\", csv_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Analyse des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Scores moyens (0‚Äì1):\n",
      " - faithfulness: 0.847\n",
      " - answer_correctness: 0.829\n",
      " - answer_relevancy: 0.929\n",
      " - context_precision: 0.861\n",
      " - context_recall: 1.000\n",
      "Synth√®se enregistr√©e -> outputs/ragas_summary.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# D√©tection du bon nom de colonne pour la pertinence\n",
    "rel_col = \"response_relevancy\" if \"response_relevancy\" in df_results.columns else (\n",
    "    \"answer_relevancy\" if \"answer_relevancy\" in df_results.columns else None\n",
    ")\n",
    "\n",
    "wanted_cols = [\"faithfulness\", \"answer_correctness\", \"context_precision\", \"context_recall\"]\n",
    "if rel_col:\n",
    "    wanted_cols.insert(2, rel_col)\n",
    "\n",
    "present = [c for c in wanted_cols if c in df_results.columns]\n",
    "summary = {c: float(np.nanmean(df_results[c])) for c in present}\n",
    "\n",
    "print(\"üìä Scores moyens (0‚Äì1):\")\n",
    "for k, v in summary.items():\n",
    "    print(f\" - {k}: {v:.3f}\")\n",
    "\n",
    "summary_out = os.path.join(OUTPUT_DIR, \"ragas_summary.json\")\n",
    "with open(summary_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"provider\": RAGAS_LLM_PROVIDER,\n",
    "        \"model\": {\n",
    "            \"openai\": OPENAI_MODEL,\n",
    "            \"claude\": CLAUDE_MODEL,\n",
    "            \"gemini\": GEMINI_MODEL,\n",
    "            \"ollama\": OLLAMA_MODEL,\n",
    "        }.get(RAGAS_LLM_PROVIDER, \"n/a\"),\n",
    "        \"scores\": summary,\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Synth√®se enregistr√©e ->\", summary_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
